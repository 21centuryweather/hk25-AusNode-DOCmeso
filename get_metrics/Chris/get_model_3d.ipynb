{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a507d3d0-7828-419a-a73b-86ffd412fb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/pyproj/network.py:59: UserWarning: pyproj unable to set PROJ database path.\n",
      "  _set_context_ca_bundle_path(ca_bundle_path)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# ----------------------------------------------------------------------\n",
    "#  Function to save model data regridded to IMERG grid for certain region\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "    \n",
    "# == imports ==\n",
    "# -- packages --\n",
    "import xarray as xr\n",
    "import os\n",
    "import pandas as pd\n",
    "from easygems import healpix as egh\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -- imported scripts --\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b0743b-310c-468a-bcc7-285220508751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# == post-process ==\n",
    "def process_data_further(da, process_request):\n",
    "    ''' Function to save regridded data '''\n",
    "    var_name, dataset, time_period, t_freq, lon_area, lat_area, resolution, name, _ = process_request\n",
    "    path_save = f\"/scratch/nf33/hk25_DOCmeso/{dataset}_interp/{dataset}_{var_name}_{resolution}_{time_period.replace(' ','')}_{name}.nc\"    \n",
    "    \n",
    "    try: del da.attrs[\"hiopy::enable\"]\n",
    "    except: pass\n",
    "\n",
    "    # Save as netcdf\n",
    "    #da.to_netcdf(path_save)\n",
    "    \n",
    "    #print (f\"{dataset} regridded file was saved for {time_period}\")\n",
    "    #del da\n",
    "    return da\n",
    "\n",
    "# == pre-process ==\n",
    "def pre_process(ds, process_request):\n",
    "    var_name, dataset, time_period, t_freq, lon_area, lat_area, resolution, _, _ = process_request\n",
    "\n",
    "    # -- pick out variable --    \n",
    "    da = ds[var_name]#.load()\n",
    "    \n",
    "    # -- temporally resample --\n",
    "    if t_freq == 'hrly':\n",
    "        da = da.resample(time='1h').mean()\n",
    "    elif t_freq == '3hrly':\n",
    "        da = da.resample(time='3h').mean()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # -- select region of interest --\n",
    "    da = da.sel(lon = slice(int(lon_area.split(':')[0]), int(lon_area.split(':')[1])), \n",
    "                lat = slice(int(lat_area.split(':')[0]), int(lat_area.split(':')[1]))\n",
    "                )\n",
    "    \n",
    "    return da\n",
    "\n",
    "def get_nn_lon_lat_index(nside, lons, lats):\n",
    "    \"\"\"\n",
    "    nside: integer, power of 2. The return of hp.get_nside()\n",
    "    lons: uniques values of longitudes\n",
    "    lats: uniques values of latitudes\n",
    "    returns: array with the HEALPix cells that are closest to the lon/lat grid\n",
    "    \"\"\"\n",
    "    lons2, lats2 = np.meshgrid(lons, lats)\n",
    "    return xr.DataArray(\n",
    "        hp.ang2pix(nside, lons2, lats2, nest = True, lonlat = True),\n",
    "        coords=[(\"lat\", lats), (\"lon\", lons)],\n",
    "    )\n",
    "\n",
    "def crop_region(ds, process_request):\n",
    "    # Select region of interest (without regridding)\n",
    "    var_name, dataset, time_period, t_freq, lon_area, lat_area, resolution, _, ds_regrid = process_request\n",
    "    Slim, Nlim = int(lat_area.split(':')[0]), int(lat_area.split(':')[1])\n",
    "    Elim, Wlim = int(lon_area.split(':')[0]), int(lon_area.split(':')[1])\n",
    "\n",
    "    print (Slim, Nlim)\n",
    "    print (Elim, Wlim)\n",
    "    # Add lat and lon info, and crop\n",
    "    ds     = ds.pipe(egh.attach_coords)\n",
    "    ds_reg = ds.where((ds[\"lat\"] > Slim) & (ds[\"lat\"] < Nlim) & (ds[\"lon\"] > Elim) & (ds[\"lon\"] < Wlim),drop=True)\n",
    "\n",
    "    print (\"region cropped\")\n",
    "    return ds_reg\n",
    "\n",
    "def regrid(ds, process_request):\n",
    "    var_name, dataset, time_period, t_freq, lon_area, lat_area, resolution, _, ds_regrid = process_request\n",
    "    \n",
    "    # -- pick out variable --    \n",
    "    da = ds[var_name]#.load()\n",
    "\n",
    "    # -- temporally resample --\n",
    "    if t_freq == 'hrly':\n",
    "        da = da.resample(time='1h').mean()\n",
    "    elif t_freq == '3hrly':\n",
    "        da = da.resample(time='3h').mean()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Find the HEALPix pixels that are closest to the IMERG grid\n",
    "    lon = ds_regrid['lon'].values\n",
    "    lat = ds_regrid['lat'].values\n",
    "\n",
    "    # nside for um simulation, it should be equal to 2**zoom\n",
    "    this_nside = hp.get_nside(da) # I have to do it to the whole domain\n",
    "    cells = get_nn_lon_lat_index(this_nside, lon, lat) \n",
    "\n",
    "    # Regridded\n",
    "    ds_regrided = da.isel(cell = cells) # regriding\n",
    "\n",
    "    return cells, ds_regrided\n",
    "\n",
    "\n",
    "def get_data(process_request, process_data_further):\n",
    "    var, dataset, time_str, t_freq, lon_area, lat_area, resolution, _, ds_regrid = process_request\n",
    "\n",
    "    # -- get file and open data --\n",
    "    \n",
    "    if dataset == \"IMERG\":\n",
    "        year, month, day = time_str.split('-')\n",
    "        folder = f'/g/data/ia39/aus-ref-clim-data-nci/gpm/data/V07/{year}'\n",
    "        if int(month) == 12 and int(day) == 23:                                     # day is missing, give previous days value\n",
    "            filename = f'3B-HHR.MS.MRG.3IMERG.{year}{month}22.V07A.nc'\n",
    "            da = xr.open_dataset(f'{folder}/{filename}')\n",
    "            da['time'] = da['time'] + pd.Timedelta(days=1)\n",
    "        elif int(month) == 12 and int(day) == 24:                                   # day is missing, give previous days value\n",
    "            filename = f'3B-HHR.MS.MRG.3IMERG.{year}{month}25.V07A.nc'\n",
    "            da = xr.open_dataset(f'{folder}/{filename}')\n",
    "            da['time'] = da['time'] - pd.Timedelta(days=1)\n",
    "        else:\n",
    "            filename = f'3B-HHR.MS.MRG.3IMERG.{year}{month}{day}.V07A.nc'\n",
    "        da = xr.open_dataset(f'{folder}/{filename}')\n",
    "    \n",
    "    elif dataset == \"UM\":\n",
    "        #folder = f'/scratch/nf33/Healpix_data/{dataset}'\n",
    "        #filename = f'data.healpix.PT1H.{resolution}.zarr'\n",
    "        folder = f'/g/data/qx55/uk_node/glm.n2560_RAL3p3/'\n",
    "        filename = f'data.healpix.PT{t_freq}.{resolution}.zarr'\n",
    "        da  = xr.open_zarr(f'{folder}/{filename}')\n",
    "        da  = da.sel(time = time_str) if time_str != \"All\" else da \n",
    "        \n",
    "    else: # For ICON\n",
    "        #folder   = f'/scratch/nf33/Healpix_data/{dataset}'\n",
    "        #filename = f'data.healpix.PT1H.{resolution}.zarr'\n",
    "        folder = f'/g/data/qx55/germany_node/d3hp003.zarr/'\n",
    "        filename = f'PT{t_freq}_point_{resolution}_atm.zarr'\n",
    "        da  = xr.open_zarr(f'{folder}/{filename}')\n",
    "        da  = da.sel(time = time_str) if time_str != \"All\" else da \n",
    "        \n",
    "    # -- pre-process --\n",
    "    if dataset == \"IMERG\":\n",
    "        da = pre_process(da, process_request)\n",
    "        return da\n",
    "\n",
    "    else:\n",
    "        #da = crop_region(da, process_request)\n",
    "        if var == \"pr\":\n",
    "            cells_inside, da = regrid(da, process_request)\n",
    "            return cells_inside, da\n",
    "        else:\n",
    "            return da\n",
    "        #da = process_data_further(da, process_request)\n",
    "        \n",
    "        #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e0e72b-1989-4fe1-b0df-d1d83eb0c679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_3d(dataset_, times = \"All\"): #\"UM\" or \"ICON\" time_str: \"2020-02-01\"\n",
    "    # exit()\n",
    "\n",
    "    # Get IMERG data: any date\n",
    "    var =           'precipitation'\n",
    "    dataset =       'IMERG'\n",
    "    time_str =      '2020-03-01'\n",
    "    t_freq =        'hourly'\n",
    "    lon_area =      '100:149'\n",
    "    lat_area =      '-10:10'\n",
    "    resolution =    0.1\n",
    "\n",
    "    process_request = [var, dataset, time_str, t_freq, lon_area, lat_area, resolution, None, None]\n",
    "    ds_imerg = get_data(process_request, process_data_further)\n",
    "    \n",
    "    \n",
    "    print (\"IMERG data was read\")\n",
    "    \n",
    "    # Run precipitation to get grids: one hour\n",
    "    dataset = dataset_\n",
    "    var   =         'pr'\n",
    "    time_str =      '2020-03-01 00:00' # or \"All\"\n",
    "    if dataset == \"ICON\": t_freq = '1H' if var == \"pr\" else \"6H\"\n",
    "    else: t_freq = '1H' if var == \"pr\" else \"3H\"\n",
    "    lon_area =      '100:149'\n",
    "    lat_area =      '-10:10'\n",
    "    resolution =    'z9'\n",
    "    name       =    \"MarCont\" # Name to add to the saved file\n",
    "    \n",
    "    process_request = [var, dataset, time_str, t_freq, lon_area, lat_area, resolution, name, ds_imerg]\n",
    "    \n",
    "    if var == \"pr\":\n",
    "        cells_inside, ds_model = get_data(process_request, process_data_further)\n",
    "    else:    \n",
    "        ds_model = get_data(process_request, process_data_further)\n",
    "        \n",
    "    print (f\"{dataset} {var} data was read to regrid\")\n",
    "\n",
    "    # Run all other variables in 3D, regrid them after\n",
    "    var   =         \"ta\"\n",
    "    time_str =      times # or \"All\"\n",
    "    if dataset == \"ICON\": t_freq = '1H' if var == \"pr\" else \"6H\"\n",
    "    else: t_freq = '1H' if var == \"pr\" else \"3H\"\n",
    "    \n",
    "    # Running for one day\n",
    "    process_request = [var, dataset, time_str, t_freq, lon_area, lat_area, resolution, name, ds_imerg]\n",
    "    \n",
    "    if var == \"pr\":\n",
    "        cells_inside, ds_model = get_data(process_request, process_data_further)\n",
    "    else:    \n",
    "        ds_model = get_data(process_request, process_data_further)\n",
    "\n",
    "    print (f\"{dataset} 3d data was read \")\n",
    "\n",
    "    # Select some cells\n",
    "    ds_model = ds_model.isel(cell = cells_inside)\n",
    "\n",
    "    # Renaming: CF compilant    \n",
    "    ds_model = ds_model.rename({\"lat\":\"latitude\", \"lon\":\"longitude\", \"pressure\":\"level\"})\n",
    "\n",
    "    # Add atributes\n",
    "    ds_model[\"latitude\"].attrs  = {\"units\": \"degrees_north\", \"long_name\":\"latitude\"}\n",
    "    ds_model[\"longitude\"].attrs = {\"units\": \"degrees_east\", \"long_name\":\"longitude\"}\n",
    "\n",
    "    if dataset == \"ICON\": \n",
    "        ds_model[\"level\"].attrs     = {\"units\": \"Pa\", \"long_name\":\"pressure level\"}\n",
    "    elif dataset == \"UM\":\n",
    "        ds_model[\"level\"].attrs     = {\"units\": \"hPa\", \"long_name\":\"pressure level\"}\n",
    "\n",
    "    # Drop\n",
    "    ds_model = ds_model.drop_vars(\"cell\")\n",
    "    ds_model = ds_model.drop_vars(\"crs\")\n",
    "    \n",
    "    return ds_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e62508-9310-4ba2-bfd4-8dab789230ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/g/data/ia39/aus-ref-clim-data-nci/gpm/data/V07/2020/3B-HHR.MS.MRG.3IMERG.20200301.V07A.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/file_manager.py:211\u001b[39m, in \u001b[36mCachingFileManager._acquire_with_cache_info\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/lru_cache.py:56\u001b[39m, in \u001b[36mLRUCache.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m._cache.move_to_end(key)\n",
      "\u001b[31mKeyError\u001b[39m: [<class 'netCDF4._netCDF4.Dataset'>, ('/g/data/ia39/aus-ref-clim-data-nci/gpm/data/V07/2020/3B-HHR.MS.MRG.3IMERG.20200301.V07A.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '2726cff7-2a19-4088-8c3e-0fa04b602c0d']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds_model = \u001b[43mget_model_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUM\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2020-02-01\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mget_model_3d\u001b[39m\u001b[34m(dataset_, times)\u001b[39m\n\u001b[32m     11\u001b[39m resolution =    \u001b[32m0.1\u001b[39m\n\u001b[32m     13\u001b[39m process_request = [var, dataset, time_str, t_freq, lon_area, lat_area, resolution, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m ds_imerg = \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_data_further\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mIMERG data was read\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Run precipitation to get grids: one hour\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(process_request, process_data_further)\u001b[39m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    112\u001b[39m         filename = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m3B-HHR.MS.MRG.3IMERG.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.V07A.nc\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     da = \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dataset == \u001b[33m\"\u001b[39m\u001b[33mUM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m#folder = f'/scratch/nf33/Healpix_data/{dataset}'\u001b[39;00m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m#filename = f'data.healpix.PT1H.{resolution}.zarr'\u001b[39;00m\n\u001b[32m    118\u001b[39m     folder = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m/g/data/qx55/uk_node/glm.n2560_RAL3p3/\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/api.py:687\u001b[39m, in \u001b[36mopen_dataset\u001b[39m\u001b[34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[39m\n\u001b[32m    675\u001b[39m decoders = _resolve_decoders_kwargs(\n\u001b[32m    676\u001b[39m     decode_cf,\n\u001b[32m    677\u001b[39m     open_backend_dataset_parameters=backend.open_dataset_parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    683\u001b[39m     decode_coords=decode_coords,\n\u001b[32m    684\u001b[39m )\n\u001b[32m    686\u001b[39m overwrite_encoded_chunks = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33moverwrite_encoded_chunks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m backend_ds = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    693\u001b[39m ds = _dataset_from_backend_dataset(\n\u001b[32m    694\u001b[39m     backend_ds,\n\u001b[32m    695\u001b[39m     filename_or_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    705\u001b[39m     **kwargs,\n\u001b[32m    706\u001b[39m )\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:666\u001b[39m, in \u001b[36mNetCDF4BackendEntrypoint.open_dataset\u001b[39m\u001b[34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, auto_complex, lock, autoclose)\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_dataset\u001b[39m(\n\u001b[32m    645\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    646\u001b[39m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m | os.PathLike[Any] | ReadBuffer | AbstractDataStore,\n\u001b[32m   (...)\u001b[39m\u001b[32m    663\u001b[39m     autoclose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    664\u001b[39m ) -> Dataset:\n\u001b[32m    665\u001b[39m     filename_or_obj = _normalize_path(filename_or_obj)\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     store = \u001b[43mNetCDF4DataStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m     store_entrypoint = StoreBackendEntrypoint()\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:452\u001b[39m, in \u001b[36mNetCDF4DataStore.open\u001b[39m\u001b[34m(cls, filename, mode, format, group, clobber, diskless, persist, auto_complex, lock, lock_maker, autoclose)\u001b[39m\n\u001b[32m    448\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauto_complex\u001b[39m\u001b[33m\"\u001b[39m] = auto_complex\n\u001b[32m    449\u001b[39m manager = CachingFileManager(\n\u001b[32m    450\u001b[39m     netCDF4.Dataset, filename, mode=mode, kwargs=kwargs\n\u001b[32m    451\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:393\u001b[39m, in \u001b[36mNetCDF4DataStore.__init__\u001b[39m\u001b[34m(self, manager, group, mode, lock, autoclose)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28mself\u001b[39m._group = group\n\u001b[32m    392\u001b[39m \u001b[38;5;28mself\u001b[39m._mode = mode\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28mself\u001b[39m.format = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mds\u001b[49m.data_model\n\u001b[32m    394\u001b[39m \u001b[38;5;28mself\u001b[39m._filename = \u001b[38;5;28mself\u001b[39m.ds.filepath()\n\u001b[32m    395\u001b[39m \u001b[38;5;28mself\u001b[39m.is_remote = is_remote_uri(\u001b[38;5;28mself\u001b[39m._filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:461\u001b[39m, in \u001b[36mNetCDF4DataStore.ds\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:455\u001b[39m, in \u001b[36mNetCDF4DataStore._acquire\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/file_manager.py:199\u001b[39m, in \u001b[36mCachingFileManager.acquire_context\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;129m@contextlib\u001b[39m.contextmanager\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    198\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     file, cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/nf33/public/miniconda/envs/digital_earths_env/lib/python3.12/site-packages/xarray/backends/file_manager.py:217\u001b[39m, in \u001b[36mCachingFileManager._acquire_with_cache_info\u001b[39m\u001b[34m(self, needs_lock)\u001b[39m\n\u001b[32m    215\u001b[39m     kwargs = kwargs.copy()\n\u001b[32m    216\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._mode\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode == \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28mself\u001b[39m._mode = \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2521\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Dataset.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:2158\u001b[39m, in \u001b[36mnetCDF4._netCDF4._ensure_nc_success\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/g/data/ia39/aus-ref-clim-data-nci/gpm/data/V07/2020/3B-HHR.MS.MRG.3IMERG.20200301.V07A.nc'"
     ]
    }
   ],
   "source": [
    "ds_model = get_model_3d(\"UM\", \"2020-02-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362b5e0-a25d-41b2-9d6e-ad6547146991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digital_earths_kernel",
   "language": "python",
   "name": "digital_earths_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
